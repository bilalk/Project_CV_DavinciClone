{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c17d56f-ff77-4c61-b664-cc1c5d3b0dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.179-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.1.2)\n",
      "Collecting matplotlib>=3.3.0 (from ultralytics)\n",
      "  Downloading matplotlib-3.10.5-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting opencv-python>=4.6.0 (from ultralytics)\n",
      "  Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
      "Collecting scipy>=1.4.1 (from ultralytics)\n",
      "  Downloading scipy-1.16.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.8.0.dev20250319+cu128)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.22.0.dev20250319+cu128)\n",
      "Collecting tqdm>=4.64.0 (from ultralytics)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (7.0.0)\n",
      "Collecting py-cpuinfo (from ultralytics)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting pandas>=1.1.4 (from ultralytics)\n",
      "  Downloading pandas-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.15-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=3.3.0->ultralytics)\n",
      "  Downloading contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=3.3.0->ultralytics)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3.3.0->ultralytics)\n",
      "  Downloading fonttools-4.59.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (108 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib>=3.3.0->ultralytics)\n",
      "  Downloading kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas>=1.1.4->ultralytics)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.1.4->ultralytics)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.8.0.87 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.8.0.87)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.25.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.25.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.0.11)\n",
      "Requirement already satisfied: pytorch-triton==3.3.0+git96316ce5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.3.0+git96316ce5)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-triton==3.3.0+git96316ce5->torch>=1.8.0->ultralytics) (77.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Downloading ultralytics-8.3.179-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.10.5-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (67.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.16.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.4/35.4 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading ultralytics_thop-2.0.15-py3-none-any.whl (28 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (355 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.59.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, py-cpuinfo, tzdata, tqdm, scipy, opencv-python, kiwisolver, fonttools, cycler, contourpy, pandas, matplotlib, ultralytics-thop, ultralytics\n",
      "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.59.1 kiwisolver-1.4.9 matplotlib-3.10.5 opencv-python-4.12.0.88 pandas-2.3.1 py-cpuinfo-9.0.0 pytz-2025.2 scipy-1.16.1 tqdm-4.67.1 tzdata-2025.2 ultralytics-8.3.179 ultralytics-thop-2.0.15\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting ultralytics==8.0.196\n",
      "  Downloading ultralytics-8.0.196-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting deep-sort-realtime==1.3.2\n",
      "  Downloading deep_sort_realtime-1.3.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting scenedetect==0.6.1\n",
      "  Downloading scenedetect-0.6.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.1.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (7.0.0)\n",
      "Collecting GPUtil\n",
      "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.8.0.dev20250319+cu128)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.22.0.dev20250319+cu128)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0.dev20250319+cu128)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.0.196) (3.10.5)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.0.196) (11.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.0.196) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.0.196) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.0.196) (1.16.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.0.196) (4.67.1)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.0.196) (2.3.1)\n",
      "Collecting seaborn>=0.11.0 (from ultralytics==8.0.196)\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.0.196) (9.0.0)\n",
      "Collecting thop>=0.1.1 (from ultralytics==8.0.196)\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting Click (from scenedetect==0.6.1)\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting appdirs (from scenedetect==0.6.1)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.8.0.87 in /usr/local/lib/python3.11/dist-packages (from torch) (9.8.0.87)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /usr/local/lib/python3.11/dist-packages (from torch) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /usr/local/lib/python3.11/dist-packages (from torch) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.25.1 in /usr/local/lib/python3.11/dist-packages (from torch) (2.25.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.0.11)\n",
      "Requirement already satisfied: pytorch-triton==3.3.0+git96316ce5 in /usr/local/lib/python3.11/dist-packages (from torch) (3.3.0+git96316ce5)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-triton==3.3.0+git96316ce5->torch) (77.0.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (4.59.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics==8.0.196) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics==8.0.196) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.0.196) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.0.196) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.0.196) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.0.196) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.0.196) (1.16.0)\n",
      "Downloading ultralytics-8.0.196-py3-none-any.whl (631 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m631.1/631.1 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading deep_sort_realtime-1.3.2-py3-none-any.whl (8.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scenedetect-0.6.1-py3-none-any.whl (115 kB)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Building wheels for collected packages: GPUtil\n",
      "  Building wheel for GPUtil (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for GPUtil: filename=gputil-1.4.0-py3-none-any.whl size=7435 sha256=8a4827bffbc419335e4cfb14e4e53aeea98bf920b67bb948526a12e49f8c7330\n",
      "  Stored in directory: /root/.cache/pip/wheels/2b/4d/8f/55fb4f7b9b591891e8d3f72977c4ec6c7763b39c19f0861595\n",
      "Successfully built GPUtil\n",
      "Installing collected packages: GPUtil, appdirs, Click, scenedetect, deep-sort-realtime, seaborn, thop, ultralytics\n",
      "  Attempting uninstall: ultralytics\n",
      "    Found existing installation: ultralytics 8.3.179\n",
      "    Uninstalling ultralytics-8.3.179:\n",
      "      Successfully uninstalled ultralytics-8.3.179\n",
      "Successfully installed Click-8.2.1 GPUtil-1.4.0 appdirs-1.4.4 deep-sort-realtime-1.3.2 scenedetect-0.6.1 seaborn-0.13.2 thop-0.1.1.post2209072238 ultralytics-8.0.196\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Libraries and Dependencies installations..\n",
    "\n",
    "!pip install -U ultralytics\n",
    "!pip install ultralytics==8.0.196 \\\n",
    "            deep-sort-realtime==1.3.2 \\\n",
    "            scenedetect==0.6.1 \\\n",
    "            opencv-python \\\n",
    "            numpy \\\n",
    "            psutil \\\n",
    "            GPUtil \\\n",
    "            torch \\\n",
    "            torchvision \\\n",
    "            torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8db303-04f8-4a82-b29c-cdb203f1774d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bd0d31-f7d9-4356-862e-1c3277196d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4004022-5802-46a8-9cbb-eb2f7579b41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO model loaded successfully with weights_only=False.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3047bea4-990d-4d01-a37c-e2fc0c30e3cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "252f2b58-3296-41f0-8ad7-80437c8824ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1-It9RlqOYAEIDbKB5sHFOlaYRRKUmiCp\n",
      "From (redirected): https://drive.google.com/uc?id=1-It9RlqOYAEIDbKB5sHFOlaYRRKUmiCp&confirm=t&uuid=d2ca2a68-55f4-455e-bcb4-16dc356bd19f\n",
      "To: /workspace/input_file.mp4\n",
      "100%|████████████████████████████████████████| 285M/285M [00:04<00:00, 58.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install -q gdown\n",
    "!gdown 1-It9RlqOYAEIDbKB5sHFOlaYRRKUmiCp -O input_file.mp4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85064a4-8048-454c-8550-9b5277d721e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6943e3c7-5ec7-4ccd-9da3-ab726394cf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imageio-ffmpeg\n",
      "  Downloading imageio_ffmpeg-0.6.0-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Downloading imageio_ffmpeg-0.6.0-py3-none-manylinux2014_x86_64.whl (29.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.5/29.5 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: imageio-ffmpeg\n",
      "Successfully installed imageio-ffmpeg-0.6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install imageio-ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4028d53a-78ad-4eb2-a06d-cf6491d5f8c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Original torch.load ko safe rakhna\n",
    "_torch_load_orig = torch.load\n",
    "\n",
    "def torch_load_safe(f, *args, **kwargs):\n",
    "    # Sirf tab patch kare jab weights_only explicitly set na ho\n",
    "    if \"weights_only\" not in kwargs:\n",
    "        kwargs[\"weights_only\"] = False\n",
    "    return _torch_load_orig(f, *args, **kwargs)\n",
    "\n",
    "# Ek baar hi patch kare\n",
    "if torch.load is not torch_load_safe:\n",
    "    torch.load = torch_load_safe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ffe49b9-6037-443c-a59a-2ad2e3501217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading YOLO model with temporary safe loader (weights_only=False)...\n",
      "YOLO loaded successfully (temporary loader restored afterwards).\n",
      "Starting processing: workspace/input_file.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VideoManager is deprecated and will be removed.\n",
      "[NULL @ 0x1a5342c0] Invalid NAL unit size (22294813 > 73540).\n",
      "[NULL @ 0x1a5342c0] missing picture in access unit with size 73544\n",
      "[h264 @ 0xa6d4cc0] Invalid NAL unit size (22294813 > 73540).\n",
      "[h264 @ 0xa6d4cc0] Error splitting the input into NAL units.\n",
      "[NULL @ 0x1a5342c0] Invalid NAL unit size (196608 > 43610).\n",
      "[NULL @ 0x1a5342c0] missing picture in access unit with size 43614\n",
      "[h264 @ 0x12e4e1c0] Invalid NAL unit size (196608 > 43610).\n",
      "[h264 @ 0x12e4e1c0] Error splitting the input into NAL units.\n",
      "[NULL @ 0x1a5342c0] Invalid NAL unit size (-547593495 > 20550).\n",
      "[NULL @ 0x1a5342c0] missing picture in access unit with size 20554\n",
      "[h264 @ 0x50d99c80] Invalid NAL unit size (-547593495 > 20550).\n",
      "[h264 @ 0x50d99c80] Error splitting the input into NAL units.\n",
      "[NULL @ 0x1a5342c0] Invalid NAL unit size (8029744 > 51887).\n",
      "[NULL @ 0x1a5342c0] missing picture in access unit with size 51891\n",
      "[h264 @ 0x54fbfe80] Invalid NAL unit size (8029744 > 51887).\n",
      "[h264 @ 0x54fbfe80] Error splitting the input into NAL units.\n",
      "[h264 @ 0x5561db00] mmco: unref short failure\n",
      "[h264 @ 0x5561db00] mmco: unref short failure\n",
      "[h264 @ 0x5561db00] mmco: unref short failure\n",
      "[h264 @ 0x5561db00] mmco: unref short failure\n",
      "[h264 @ 0x5561db00] mmco: unref short failure\n",
      "[h264 @ 0x5561db00] mmco: unref short failure\n",
      "[h264 @ 0x5561db00] mmco: unref short failure\n",
      "[h264 @ 0x5561db00] mmco: unref short failure\n",
      "[h264 @ 0x5561db00] mmco: unref short failure\n",
      "[h264 @ 0x5561db00] mmco: unref short failure\n",
      "[h264 @ 0x5561db00] mmco: unref short failure\n",
      "[h264 @ 0x5561db00] mmco: unref short failure\n",
      "[h264 @ 0x5561db00] mmco: unref short failure\n",
      "[h264 @ 0x5561db00] mmco: unref short failure\n",
      "[h264 @ 0x5561db00] mmco: unref short failure\n",
      "[h264 @ 0x5561db00] mmco: unref short failure\n",
      "[h264 @ 0x5561db00] mmco: unref short failure\n",
      "[h264 @ 0x5561db00] mmco: unref short failure\n",
      "[h264 @ 0x5561db00] mmco: unref short failure\n",
      "[h264 @ 0x5561db00] mmco: unref short failure\n",
      "[h264 @ 0x5561db00] mmco: unref short failure\n",
      "[NULL @ 0x532f0c80] Invalid NAL unit size (22294813 > 73540).\n",
      "[NULL @ 0x532f0c80] missing picture in access unit with size 73544\n",
      "[h264 @ 0x50e39ac0] Invalid NAL unit size (22294813 > 73540).\n",
      "[h264 @ 0x50e39ac0] Error splitting the input into NAL units.\n",
      "[NULL @ 0x532f0c80] Invalid NAL unit size (196608 > 43610).\n",
      "[NULL @ 0x532f0c80] missing picture in access unit with size 43614\n",
      "[h264 @ 0x534e8800] Invalid NAL unit size (196608 > 43610).\n",
      "[h264 @ 0x534e8800] Error splitting the input into NAL units.\n",
      "[NULL @ 0x532f0c80] Invalid NAL unit size (-547593495 > 20550).\n",
      "[NULL @ 0x532f0c80] missing picture in access unit with size 20554\n",
      "[h264 @ 0x5250d000] Invalid NAL unit size (-547593495 > 20550).\n",
      "[h264 @ 0x5250d000] Error splitting the input into NAL units.\n",
      "ffmpeg version 7.0.2-static https://johnvansickle.com/ffmpeg/  Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with gcc 8 (Debian 8.3.0-6)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-debug --disable-ffplay --disable-indev=sndio --disable-outdev=sndio --cc=gcc --enable-fontconfig --enable-frei0r --enable-gnutls --enable-gmp --enable-libgme --enable-gray --enable-libaom --enable-libfribidi --enable-libass --enable-libvmaf --enable-libfreetype --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-librubberband --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libvorbis --enable-libopus --enable-libtheora --enable-libvidstab --enable-libvo-amrwbenc --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libdav1d --enable-libxvid --enable-libzvbi --enable-libzimg\n",
      "  libavutil      59.  8.100 / 59.  8.100\n",
      "  libavcodec     61.  3.100 / 61.  3.100\n",
      "  libavformat    61.  1.100 / 61.  1.100\n",
      "  libavdevice    61.  1.100 / 61.  1.100\n",
      "  libavfilter    10.  1.100 / 10.  1.100\n",
      "  libswscale      8.  1.100 /  8.  1.100\n",
      "  libswresample   5.  1.100 /  5.  1.100\n",
      "  libpostproc    58.  1.100 / 58.  1.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'output_intermediate.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf59.27.100\n",
      "  Duration: 00:08:22.42, start: 0.000000, bitrate: 13525 kb/s\n",
      "  Stream #0:0[0x1](und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 1920x1080 [SAR 1:1 DAR 16:9], 13524 kb/s, 24 fps, 24 tbr, 12288 tbn (default)\n",
      "      Metadata:\n",
      "        handler_name    : VideoHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x7d287c0] using SAR=1/1\n",
      "[libx264 @ 0x7d287c0] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x7d287c0] profile High, level 5.0, 4:2:0, 8-bit\n",
      "[libx264 @ 0x7d287c0] 264 - core 164 r3191 4613ac3 - H.264/MPEG-4 AVC codec - Copyleft 2003-2024 - http://www.videolan.org/x264.html - options: cabac=1 ref=5 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=8 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=2 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=34 lookahead_threads=5 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=3 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=24 scenecut=40 intra_refresh=0 rc_lookahead=50 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'output_final.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf61.1.100\n",
      "  Stream #0:0(und): Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 1920x1080 [SAR 1:1 DAR 16:9], q=2-31, 24 fps, 12288 tbn (default)\n",
      "      Metadata:\n",
      "        handler_name    : VideoHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : Lavc61.3.100 libx264\n",
      "      Side data:\n",
      "        cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=12039 fps=6.3 q=-1.0 size=  358400KiB time=00:08:21.54 bitrate=5854.0kbits/s speed=0.264x     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: output_final.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[out#0/mp4 @ 0x7d08a40] video:359315KiB audio:0KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.022331%\n",
      "frame=12058 fps=6.3 q=-1.0 Lsize=  359396KiB time=00:08:22.33 bitrate=5861.0kbits/s speed=0.264x    \n",
      "[libx264 @ 0x7d287c0] frame I:857   Avg QP:19.42  size: 46383\n",
      "[libx264 @ 0x7d287c0] frame P:9504  Avg QP:22.26  size: 29586\n",
      "[libx264 @ 0x7d287c0] frame B:1697  Avg QP:23.64  size: 27695\n",
      "[libx264 @ 0x7d287c0] consecutive B-frames: 76.8% 11.7%  4.7%  6.8%\n",
      "[libx264 @ 0x7d287c0] mb I  I16..4: 25.4% 73.4%  1.2%\n",
      "[libx264 @ 0x7d287c0] mb P  I16..4: 13.4% 40.3%  0.5%  P16..4: 21.8%  3.6%  1.2%  0.0%  0.0%    skip:19.3%\n",
      "[libx264 @ 0x7d287c0] mb B  I16..4:  3.5% 13.6%  0.7%  B16..8: 28.6%  7.2%  1.2%  direct: 3.6%  skip:41.6%  L0:57.7% L1:34.0% BI: 8.3%\n",
      "[libx264 @ 0x7d287c0] 8x8 transform intra:74.4% inter:87.7%\n",
      "[libx264 @ 0x7d287c0] direct mvs  spatial:99.8% temporal:0.2%\n",
      "[libx264 @ 0x7d287c0] coded y,uvDC,uvAC intra: 38.9% 47.0% 4.0% inter: 14.9% 18.9% 0.2%\n",
      "[libx264 @ 0x7d287c0] i16 v,h,dc,p: 25% 37% 12% 26%\n",
      "[libx264 @ 0x7d287c0] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 30% 25% 22%  3%  3%  4%  4%  4%  4%\n",
      "[libx264 @ 0x7d287c0] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 17% 18% 10%  6% 12% 11% 11%  7%  8%\n",
      "[libx264 @ 0x7d287c0] i8c dc,h,v,p: 39% 33% 20%  9%\n",
      "[libx264 @ 0x7d287c0] Weighted P-Frames: Y:0.9% UV:0.8%\n",
      "[libx264 @ 0x7d287c0] ref P L0: 75.3% 11.3%  8.0%  2.7%  1.7%  1.0%  0.0%\n",
      "[libx264 @ 0x7d287c0] ref B L0: 87.1%  8.6%  3.7%  0.6%\n",
      "[libx264 @ 0x7d287c0] ref B L1: 98.6%  1.4%\n",
      "[libx264 @ 0x7d287c0] kb/s:5858.70\n"
     ]
    }
   ],
   "source": [
    "# === Single cell: Safe YOLO load (no recursion) + full processing ===\n",
    "import os, time, psutil, platform, subprocess\n",
    "import imageio_ffmpeg as ffmpeg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import GPUtil\n",
    "import torch\n",
    "from functools import partial\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "from scenedetect import VideoManager, SceneManager\n",
    "from scenedetect.detectors import ContentDetector\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "CONFIG = {\n",
    "    \"video_path\": \"workspace/input_file.mp4\",           # change to your input\n",
    "    \"output_path\": \"output_intermediate.mp4\",\n",
    "    \"final_output_path\": \"output_final.mp4\",\n",
    "    \"target_classes\": [\"person\", \"car\"],\n",
    "    \"yolo_model\": \"yolov8x.pt\",\n",
    "    \"conf_threshold\": 0.35,\n",
    "    \"zoom_min\": 2.2,\n",
    "    \"zoom_max\": 3.4,\n",
    "    \"scene_threshold\": 30.0,\n",
    "    \"fps\": 24,\n",
    "    \"deep_sort\": {\"max_age\": 30, \"n_init\": 3, \"max_iou_distance\": 0.7},\n",
    "    \"yolo_img_size\": 640,\n",
    "    \"smoothing_factor\": 0.2,\n",
    "    \"zoom_floor_frames\": 10\n",
    "}\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ---- Safe loader: temporarily force weights_only=False while loading YOLO ----\n",
    "def safe_load_yolo(yolo_path, device=None):\n",
    "    \"\"\"\n",
    "    Temporarily call torch.load with weights_only=False while constructing the model,\n",
    "    then restore the original torch.load implementation. This avoids persistent\n",
    "    monkey-patching and prevents recursion problems.\n",
    "    \"\"\"\n",
    "    _orig_load = torch.load\n",
    "    try:\n",
    "        # Bind weights_only=False to the original loader via partial\n",
    "        torch.load = partial(_orig_load, weights_only=False)\n",
    "        print(\"Loading YOLO model with temporary safe loader (weights_only=False)...\")\n",
    "        model = YOLO(yolo_path)\n",
    "        if device:\n",
    "            model.to(device)\n",
    "        print(\"YOLO loaded successfully (temporary loader restored afterwards).\")\n",
    "        return model\n",
    "    finally:\n",
    "        # Restore original torch.load no matter what\n",
    "        torch.load = _orig_load\n",
    "\n",
    "# ----- Load models safely -----\n",
    "model = safe_load_yolo(CONFIG[\"yolo_model\"], device=device)\n",
    "deepsort = DeepSort(**CONFIG[\"deep_sort\"])\n",
    "\n",
    "# ---------------- UTILS ----------------\n",
    "def detect_scenes(video_path, threshold):\n",
    "    video_manager = VideoManager([video_path])\n",
    "    scene_manager = SceneManager()\n",
    "    scene_manager.add_detector(ContentDetector(threshold=threshold))\n",
    "    video_manager.set_duration()\n",
    "    video_manager.start()\n",
    "    scene_manager.detect_scenes(frame_source=video_manager)\n",
    "    scene_list = scene_manager.get_scene_list()\n",
    "    video_manager.release()\n",
    "    return [(int(start.get_frames()), int(end.get_frames())) for start, end in scene_list]\n",
    "\n",
    "def crop_zoom(frame, cx, cy, zoom):\n",
    "    h, w = frame.shape[:2]\n",
    "    nw, nh = int(w / zoom), int(h / zoom)\n",
    "    x1, y1 = max(0, cx - nw // 2), max(0, cy - nh // 2)\n",
    "    x2, y2 = min(w, x1 + nw), min(h, y1 + nh)\n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return frame\n",
    "    return cv2.resize(frame[y1:y2, x1:x2], (w, h))\n",
    "\n",
    "def ema_smooth(prev, current, alpha):\n",
    "    return current if prev is None else alpha * current + (1 - alpha) * prev\n",
    "\n",
    "def optical_flow_center(prev_frame, curr_frame, prev_center):\n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    curr_gray = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY)\n",
    "    p0 = np.array([[prev_center]], dtype=np.float32)\n",
    "    p1, st, _ = cv2.calcOpticalFlowPyrLK(prev_gray, curr_gray, p0, None)\n",
    "    if p1 is not None and st[0][0] == 1:\n",
    "        return int(p1[0][0][0]), int(p1[0][0][1])\n",
    "    return prev_center\n",
    "\n",
    "def smooth_with_bezier(points):\n",
    "    if len(points) < 3:\n",
    "        return points\n",
    "    x = np.arange(len(points))\n",
    "    spline = make_interp_spline(x, np.array(points), k=3)\n",
    "    return spline(np.linspace(0, len(points)-1, len(points)))\n",
    "\n",
    "# ---------------- MAIN PROCESS ----------------\n",
    "def process_video(video_path):\n",
    "    print(\"Starting processing:\", video_path)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Cannot open video: {video_path}\")\n",
    "    width, height = int(cap.get(3)), int(cap.get(4))\n",
    "    writer = cv2.VideoWriter(CONFIG[\"output_path\"], cv2.VideoWriter_fourcc(*\"mp4v\"), CONFIG[\"fps\"], (width, height))\n",
    "    scene_frames = detect_scenes(video_path, CONFIG[\"scene_threshold\"])\n",
    "    prev_center, prev_zoom, prev_frame = None, None, None\n",
    "    zoom_buffer = []\n",
    "\n",
    "    class_map = {name: idx for idx, name in model.names.items()}\n",
    "    target_ids = [class_map[c] for c in CONFIG[\"target_classes\"] if c in class_map]\n",
    "\n",
    "    for (start, end) in scene_frames:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
    "        centers_history = []\n",
    "        for _f in range(start, end + 1):\n",
    "            ret, frame = cap.read()\n",
    "            if frame is None or frame.size == 0:\n",
    "                continue\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            img = cv2.resize(frame, (CONFIG[\"yolo_img_size\"], CONFIG[\"yolo_img_size\"]))\n",
    "            results = model.predict(img, conf=CONFIG[\"conf_threshold\"], device=device, verbose=False)\n",
    "            detections = results[0].boxes.data.cpu().numpy()\n",
    "\n",
    "            track_inputs = []\n",
    "            for *xyxy, conf_, cls in detections:\n",
    "                cls_id = int(cls)\n",
    "                if cls_id in target_ids:\n",
    "                    sx, sy = width / CONFIG[\"yolo_img_size\"], height / CONFIG[\"yolo_img_size\"]\n",
    "                    x1, y1, x2, y2 = map(int, [xyxy[0]*sx, xyxy[1]*sy, xyxy[2]*sx, xyxy[3]*sy])\n",
    "                    track_inputs.append(([x1, y1, x2-x1, y2-y1], float(conf_), model.names[cls_id]))\n",
    "\n",
    "            tracks = deepsort.update_tracks(track_inputs, frame=frame)\n",
    "            if tracks:\n",
    "                centers = [\n",
    "                    (int((t.to_ltrb()[0] + t.to_ltrb()[2]) // 2),\n",
    "                     int((t.to_ltrb()[1] + t.to_ltrb()[3]) // 2))\n",
    "                    for t in tracks if t.is_confirmed()\n",
    "                ]\n",
    "                zooms = []\n",
    "                for t in tracks:\n",
    "                    if t.is_confirmed():\n",
    "                        x1, y1, x2, y2 = map(int, t.to_ltrb())\n",
    "                        area_ratio = ((x2 - x1) * (y2 - y1)) / (width * height)\n",
    "                        if area_ratio == 0:\n",
    "                            continue  # skip this track\n",
    "                        # area_ratio = ((x2-x1)*(y2-y1)) / (width * height)\n",
    "                        zooms.append(np.clip(3.0 / area_ratio, CONFIG[\"zoom_min\"], CONFIG[\"zoom_max\"]))\n",
    "            \n",
    "                if centers:  # Only process if we have at least one center\n",
    "                    avg_center = np.mean(centers, axis=0).astype(int)\n",
    "                    if prev_frame is not None:\n",
    "                        avg_center = optical_flow_center(prev_frame, frame, tuple(avg_center))\n",
    "                    avg_zoom = float(np.mean(zooms))\n",
    "            \n",
    "                    avg_center = (\n",
    "                        int(ema_smooth(prev_center[0] if prev_center else avg_center[0],\n",
    "                                       avg_center[0], CONFIG[\"smoothing_factor\"])),\n",
    "                        int(ema_smooth(prev_center[1] if prev_center else avg_center[1],\n",
    "                                       avg_center[1], CONFIG[\"smoothing_factor\"]))\n",
    "                    )\n",
    "                    avg_zoom = float(ema_smooth(prev_zoom if prev_zoom else avg_zoom,\n",
    "                                                avg_zoom, CONFIG[\"smoothing_factor\"]))\n",
    "            \n",
    "                    zoom_buffer.append(avg_zoom)\n",
    "                    if len(zoom_buffer) > CONFIG[\"zoom_floor_frames\"]:\n",
    "                        zoom_buffer.pop(0)\n",
    "                    avg_zoom = max(avg_zoom, min(zoom_buffer))\n",
    "            \n",
    "                    frame = crop_zoom(frame, avg_center[0], avg_center[1], avg_zoom)\n",
    "                    prev_center, prev_zoom, prev_frame = avg_center, avg_zoom, frame.copy()\n",
    "\n",
    "\n",
    "            writer.write(frame)\n",
    "\n",
    "        # optional: you could reprocess scene using smoothed centers if desired\n",
    "        if centers_history:\n",
    "            smoothed = smooth_with_bezier(centers_history)  # unused but available\n",
    "\n",
    "    cap.release()\n",
    "    writer.release()\n",
    "\n",
    "    # Finalize with ffmpeg re-encode (optional)\n",
    "    ffmpeg_path = ffmpeg.get_ffmpeg_exe()  # already done\n",
    "    subprocess.run([\n",
    "            ffmpeg_path, \"-y\", \"-i\", CONFIG[\"output_path\"],\n",
    "            \"-c:v\", \"libx264\", \"-crf\", \"23\", \"-preset\", \"slow\",\n",
    "            \"-r\", str(CONFIG[\"fps\"]),\n",
    "            CONFIG[\"final_output_path\"]\n",
    "        ], check=True)\n",
    "\n",
    "    # subprocess.run([\n",
    "    #     \"ffmpeg\", \"-y\", \"-i\", CONFIG[\"output_path\"],\n",
    "    #     \"-c:v\", \"libx264\", \"-crf\", \"23\", \"-preset\", \"slow\",\n",
    "    #     \"-r\", str(CONFIG[\"fps\"]),\n",
    "    #     CONFIG[\"final_output_path\"]\n",
    "    # ], check=True)\n",
    "    print(\"Finished:\", CONFIG[\"final_output_path\"])\n",
    "\n",
    "# --------------- RUN ----------------\n",
    "process_video(CONFIG[\"video_path\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3bac92-5ca3-45ad-a92f-f779788b401c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117c6161-35f8-4310-813c-b991ec01b9d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21fe415-8dc1-4f1a-8525-d8174e41184b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c240b8ca-3c22-46fd-aa36-b0f2014c9d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial Code from last work..\n",
    "\n",
    "import json, os, psutil, time, torch, GPUtil, platform\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "from scenedetect import VideoManager, SceneManager\n",
    "from scenedetect.detectors import ContentDetector\n",
    "import subprocess\n",
    "\n",
    "# -------- CONFIG --------\n",
    "CONFIG = {\n",
    "    \"video_path\": \"/content/drive/MyDrive/Colab Notebooks/input_2.mp4\",\n",
    "    \"output_path\": \"/content/drive/MyDrive/Colab Notebooks/test_output_2.mp4\",\n",
    "    \"final_output_path\": \"/content/drive/MyDrive/Colab Notebooks/with ffmpeg work/test_output_2_final.mp4\",  # after ffmpeg\n",
    "    \"target_classes_default\": [\"person\", \"car\"],\n",
    "    \"yolo_model\": \"yolov8x.pt\",\n",
    "    \"conf_threshold\": 0.35,\n",
    "    \"nms_threshold\": 0.5,\n",
    "    \"zoom_min\": 2.2,\n",
    "    \"zoom_max\": 3.4,\n",
    "    \"scene_threshold\": 30.0,\n",
    "    \"output_resolution\": (3840, 2160),  # 4K UHD\n",
    "    \"fps\": 24,\n",
    "    \"deep_sort\": {\n",
    "        \"max_age\": 30,\n",
    "        \"n_init\": 3,\n",
    "        \"max_iou_distance\": 0.7\n",
    "    },\n",
    "    \"yolo_batch_size\": 4,\n",
    "    \"yolo_img_size\": 640,\n",
    "    \"smoothing_factor\": 0.2  # for EMA smoothing of pan/zoom\n",
    "}\n",
    "\n",
    "# -------- INIT MODELS --------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = YOLO(CONFIG[\"yolo_model\"])\n",
    "model.to(device)\n",
    "deepsort = DeepSort(\n",
    "    max_age=CONFIG[\"deep_sort\"][\"max_age\"],\n",
    "    n_init=CONFIG[\"deep_sort\"][\"n_init\"],\n",
    "    max_iou_distance=CONFIG[\"deep_sort\"][\"max_iou_distance\"]\n",
    ")\n",
    "\n",
    "# -------- UTILS --------\n",
    "def detect_scenes(video_path, threshold):\n",
    "    video_manager = VideoManager([video_path])\n",
    "    scene_manager = SceneManager()\n",
    "    scene_manager.add_detector(ContentDetector(threshold=threshold))\n",
    "    video_manager.set_duration()\n",
    "    video_manager.start()\n",
    "    scene_manager.detect_scenes(frame_source=video_manager)\n",
    "    scene_list = scene_manager.get_scene_list()\n",
    "    video_manager.release()\n",
    "    return [(int(start.get_frames()), int(end.get_frames())) for start, end in scene_list]\n",
    "\n",
    "def crop_zoom(frame, center_x, center_y, zoom):\n",
    "    h, w = frame.shape[:2]\n",
    "    new_w, new_h = int(w / zoom), int(h / zoom)\n",
    "    x1, y1 = max(0, center_x - new_w // 2), max(0, center_y - new_h // 2)\n",
    "    x2, y2 = min(w, x1 + new_w), min(h, y1 + new_h)\n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return frame\n",
    "    return cv2.resize(frame[y1:y2, x1:x2], (w, h))\n",
    "\n",
    "def get_hardware_info():\n",
    "    gpu_info = GPUtil.getGPUs()[0] if torch.cuda.is_available() else None\n",
    "    return {\n",
    "        \"cpu_physical_cores\": psutil.cpu_count(logical=False),\n",
    "        \"cpu_logical_cores\": psutil.cpu_count(logical=True),\n",
    "        \"gpu_name\": gpu_info.name if gpu_info else \"CPU\",\n",
    "        \"gpu_memory_total_mb\": gpu_info.memoryTotal if gpu_info else None,\n",
    "        \"ram_total_gb\": round(psutil.virtual_memory().total / (1024**3), 2),\n",
    "        \"system\": platform.system(),\n",
    "        \"python_version\": platform.python_version()\n",
    "    }\n",
    "\n",
    "# Exponential Moving Average smoothing helper\n",
    "def ema_smooth(prev, current, alpha):\n",
    "    if prev is None:\n",
    "        return current\n",
    "    return alpha * current + (1 - alpha) * prev\n",
    "\n",
    "# Placeholder: get per-scene target classes dynamically\n",
    "def get_classes_for_scene(scene_idx):\n",
    "    # Example: alternate scenes track only 'person', others track 'person' + 'car'\n",
    "    if scene_idx % 2 == 0:\n",
    "        return [\"person\"]\n",
    "    else:\n",
    "        return [\"person\", \"car\"]\n",
    "\n",
    "# -------- MAIN PROCESS --------\n",
    "def process_video():\n",
    "    hw_info = get_hardware_info()\n",
    "    cap = cv2.VideoCapture(CONFIG[\"video_path\"])\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps_input = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    writer = cv2.VideoWriter(CONFIG[\"output_path\"], cv2.VideoWriter_fourcc(*\"mp4v\"), CONFIG[\"fps\"], (width, height))\n",
    "    scene_frames = detect_scenes(CONFIG[\"video_path\"], CONFIG[\"scene_threshold\"])\n",
    "    print(f\"Detected {len(scene_frames)} scenes.\")\n",
    "\n",
    "    print(\"Hardware info:\", hw_info)\n",
    "    print(f\"Processing video {CONFIG['video_path']} at {width}x{height} px, input FPS: {fps_input}\")\n",
    "\n",
    "    # Tracking stats init\n",
    "    frame_idx = 0\n",
    "    start_time = time.time()\n",
    "    prev_center = None\n",
    "    prev_zoom = None\n",
    "    zoom_values = []\n",
    "    jitter_values = []\n",
    "    missed_subjects = 0\n",
    "    total_tracks = 0\n",
    "    current_scene_idx = 0\n",
    "\n",
    "    for scene_idx, (scene_start, scene_end) in enumerate(scene_frames):\n",
    "        # Update target classes dynamically per scene\n",
    "        target_classes = get_classes_for_scene(scene_idx)\n",
    "        class_name_to_id = {name: idx for idx, name in model.names.items()}\n",
    "        target_class_ids = [class_name_to_id.get(c) for c in target_classes if c in class_name_to_id]\n",
    "\n",
    "        print(f\"\\nScene {scene_idx+1}/{len(scene_frames)} frames {scene_start}-{scene_end}: tracking classes {target_classes}\")\n",
    "\n",
    "        for f in range(scene_start, scene_end + 1):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # YOLO inference with batch size and img size (resize)\n",
    "            img = cv2.resize(frame, (CONFIG[\"yolo_img_size\"], CONFIG[\"yolo_img_size\"]))\n",
    "            results = model.predict(img, conf=CONFIG[\"conf_threshold\"], device=device, verbose=False, batch=CONFIG[\"yolo_batch_size\"])\n",
    "            detections = results[0].boxes.data.cpu().numpy()\n",
    "\n",
    "            track_inputs = []\n",
    "            for *xyxy, conf, cls in detections:\n",
    "                cls_id = int(cls)\n",
    "                if cls_id in target_class_ids:\n",
    "                    # Scale bbox back to original frame size\n",
    "                    scale_x = width / CONFIG[\"yolo_img_size\"]\n",
    "                    scale_y = height / CONFIG[\"yolo_img_size\"]\n",
    "                    x1, y1, x2, y2 = map(int, [xyxy[0]*scale_x, xyxy[1]*scale_y, xyxy[2]*scale_x, xyxy[3]*scale_y])\n",
    "                    track_inputs.append(([x1, y1, x2 - x1, y2 - y1], conf, model.names[cls_id]))\n",
    "\n",
    "            tracks = deepsort.update_tracks(track_inputs, frame=frame)\n",
    "\n",
    "            subjects = []\n",
    "            for track in tracks:\n",
    "                if not track.is_confirmed():\n",
    "                    continue\n",
    "                total_tracks += 1\n",
    "                x1, y1, x2, y2 = map(int, track.to_ltrb())\n",
    "                center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "                area_ratio = ((x2 - x1) * (y2 - y1)) / (width * height)\n",
    "                if area_ratio > 0:\n",
    "                    zoom = np.clip(3.0 / area_ratio, CONFIG[\"zoom_min\"], CONFIG[\"zoom_max\"])\n",
    "                    subjects.append((center_x, center_y, zoom))\n",
    "\n",
    "            if subjects:\n",
    "                avg_center_x = int(np.mean([s[0] for s in subjects]))\n",
    "                avg_center_y = int(np.mean([s[1] for s in subjects]))\n",
    "                avg_zoom_raw = np.mean([s[2] for s in subjects])\n",
    "                # Smooth center and zoom\n",
    "                avg_center_x = int(ema_smooth(prev_center[0] if prev_center else None, avg_center_x, CONFIG[\"smoothing_factor\"]))\n",
    "                avg_center_y = int(ema_smooth(prev_center[1] if prev_center else None, avg_center_y, CONFIG[\"smoothing_factor\"]))\n",
    "                avg_zoom = ema_smooth(prev_zoom, avg_zoom_raw, CONFIG[\"smoothing_factor\"])\n",
    "                prev_center = (avg_center_x, avg_center_y)\n",
    "                prev_zoom = avg_zoom\n",
    "\n",
    "                frame = crop_zoom(frame, avg_center_x, avg_center_y, avg_zoom)\n",
    "                zoom_values.append(avg_zoom)\n",
    "\n",
    "                # Jitter calc: distance between prev and current center\n",
    "                if prev_center is not None and frame_idx > 0:\n",
    "                    jitter = np.sqrt((avg_center_x - prev_center[0])**2 + (avg_center_y - prev_center[1])**2)\n",
    "                    jitter_values.append(jitter)\n",
    "\n",
    "                print(f\"[Frame {frame_idx+1}/{total_frames}] Zoom: {avg_zoom:.2f} Center: ({avg_center_x},{avg_center_y})\")\n",
    "            else:\n",
    "                missed_subjects += 1\n",
    "                zoom_values.append(None)\n",
    "                print(f\"[Frame {frame_idx+1}/{total_frames}] No subjects detected\")\n",
    "\n",
    "            writer.write(frame)\n",
    "            frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    writer.release()\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    avg_zoom = np.mean([z for z in zoom_values if z is not None]) if zoom_values else None\n",
    "    avg_jitter = np.mean(jitter_values) if jitter_values else 0\n",
    "    avg_fps = total_frames / elapsed if elapsed > 0 else 0\n",
    "\n",
    "    print(\"\\n=== Processing Summary ===\")\n",
    "    print(f\"Total frames processed: {total_frames}\")\n",
    "    print(f\"Total scenes detected: {len(scene_frames)}\")\n",
    "    print(f\"Total processing time (seconds): {elapsed:.2f}\")\n",
    "    print(f\"Average FPS: {avg_fps:.2f}\")\n",
    "    print(f\"Average zoom level: {avg_zoom:.2f}\" if avg_zoom else \"No zoom data\")\n",
    "    print(f\"Average jitter (pixels/frame): {avg_jitter:.2f}\")\n",
    "    print(f\"Missed subjects frames: {missed_subjects}\")\n",
    "    print(f\"Total confirmed tracks: {total_tracks}\")\n",
    "\n",
    "    # Call ffmpeg to enforce final format and audio encoding\n",
    "    ffmpeg_cmd = [\n",
    "        \"ffmpeg\", \"-y\", \"-i\", CONFIG[\"output_path\"],\n",
    "        \"-c:v\", \"libx264\",\n",
    "        \"-crf\", \"23\",  # adjust as needed 18-28 range\n",
    "        \"-preset\", \"slow\",\n",
    "        \"-r\", str(CONFIG[\"fps\"]),\n",
    "        \"-c:a\", \"aac\",\n",
    "        \"-b:a\", \"320k\",\n",
    "        \"-ac\", \"6\",  # 5.1 or 7.1 audio layout can be tuned here\n",
    "        CONFIG[\"final_output_path\"]\n",
    "    ]\n",
    "    print(\"\\nRunning ffmpeg to finalize output with codec and audio settings...\")\n",
    "    subprocess.run(ffmpeg_cmd, check=True)\n",
    "    print(f\"Final video saved at {CONFIG['final_output_path']}\")\n",
    "\n",
    "# ---- RUN THE PROCESS ----\n",
    "process_video()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
