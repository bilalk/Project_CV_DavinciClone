{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXovcox7XsvM",
        "outputId": "19944605-1688-4bfb-c329-54c979ff8545"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m0.9/1.0 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCreating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install -q ultralytics opencv-python-headless scenedetect ffmpeg-python deep_sort_realtime --upgrade\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import time\n",
        "from ultralytics import YOLO\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "from scenedetect import VideoManager, SceneManager\n",
        "from scenedetect.detectors import ContentDetector\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vC4BH_ddQCsk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ========== CONFIG ==========\n",
        "VIDEO_PATH = \"/content/drive/MyDrive/Colab Notebooks/input.mp4\"  # Update path as needed\n",
        "OUTPUT_PATH = \"test_output_1.mp4\"\n",
        "\n",
        "# ========== PARAMETERS ==========\n",
        "ZOOM_MIN = 2.2\n",
        "ZOOM_MAX = 3.4\n",
        "CONFIDENCE_THRESHOLD = 0.35\n",
        "SCENE_THRESHOLD = 30.0\n",
        "TARGET_CLASS = 0  # 'person'\n"
      ],
      "metadata": {
        "id": "VQQTf--0X1wV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from ultralytics import YOLO\n",
        "# ========== INIT ==========\n",
        "model = YOLO(\"yolo12x.pt\")\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "deepsort = DeepSort(max_age=30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEF9cwWvX1yt",
        "outputId": "4ecca60b-d07c-400b-dcd5-19f7a06b84d7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo12x.pt to 'yolo12x.pt': 100%|██████████| 114M/114M [00:01<00:00, 65.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def detect_scenes(video_path, threshold=SCENE_THRESHOLD):\n",
        "    video_manager = VideoManager([video_path])\n",
        "    scene_manager = SceneManager()\n",
        "    scene_manager.add_detector(ContentDetector(threshold=threshold))\n",
        "    video_manager.set_duration()\n",
        "    video_manager.start()\n",
        "    scene_manager.detect_scenes(frame_source=video_manager)\n",
        "    scene_list = scene_manager.get_scene_list()\n",
        "    scene_frames = [(int(start.get_frames()), int(end.get_frames())) for start, end in scene_list]\n",
        "    video_manager.release()\n",
        "    return scene_frames\n"
      ],
      "metadata": {
        "id": "EHUdWo3LX11N"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def crop_zoom(frame, center_x, center_y, zoom):\n",
        "    h, w = frame.shape[:2]\n",
        "    new_w = int(w / zoom)\n",
        "    new_h = int(h / zoom)\n",
        "    x1 = max(0, center_x - new_w // 2)\n",
        "    y1 = max(0, center_y - new_h // 2)\n",
        "    x2 = min(w, x1 + new_w)\n",
        "    y2 = min(h, y1 + new_h)\n",
        "    if x2 - x1 <= 0 or y2 - y1 <= 0:\n",
        "        return frame\n",
        "    cropped = frame[y1:y2, x1:x2]\n",
        "    return cv2.resize(cropped, (w, h))\n"
      ],
      "metadata": {
        "id": "gbHtiG4QX13m"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def process_video(video_path, output_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    writer = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*\"mp4v\"), original_fps, (width, height))\n",
        "\n",
        "    scene_frames = detect_scenes(video_path)\n",
        "    print(f\"Detected {len(scene_frames)} scenes.\")\n",
        "\n",
        "    frame_idx = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        scene_fps = original_fps\n",
        "        for s_start, s_end in scene_frames:\n",
        "            if s_start <= frame_idx <= s_end:\n",
        "                scene_duration = (s_end - s_start) / original_fps\n",
        "                scene_fps = 30 if scene_duration > 5 else original_fps\n",
        "                break\n",
        "\n",
        "        results = model.predict(frame, conf=CONFIDENCE_THRESHOLD, device=device, verbose=False)\n",
        "        detections = results[0].boxes.data.cpu().numpy()\n",
        "        track_inputs = []\n",
        "\n",
        "        for *xyxy, conf, cls in detections:\n",
        "            if int(cls) == TARGET_CLASS:\n",
        "                x1, y1, x2, y2 = map(int, xyxy)\n",
        "                track_inputs.append(([x1, y1, x2 - x1, y2 - y1], conf, 'person'))\n",
        "\n",
        "        tracks = deepsort.update_tracks(track_inputs, frame=frame)\n",
        "\n",
        "        subjects = []\n",
        "        for track in tracks:\n",
        "            if not track.is_confirmed():\n",
        "                continue\n",
        "            x1, y1, x2, y2 = map(int, track.to_ltrb())\n",
        "            center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "            area_ratio = ((x2 - x1) * (y2 - y1)) / (width * height)\n",
        "            if area_ratio == 0:\n",
        "                continue\n",
        "            zoom = np.clip(3.0 / area_ratio, ZOOM_MIN, ZOOM_MAX)\n",
        "            subjects.append((center_x, center_y, zoom))\n",
        "\n",
        "        if subjects:\n",
        "            avg_center_x = int(np.mean([s[0] for s in subjects]))\n",
        "            avg_center_y = int(np.mean([s[1] for s in subjects]))\n",
        "            avg_zoom = np.mean([s[2] for s in subjects])\n",
        "            frame = crop_zoom(frame, avg_center_x, avg_center_y, avg_zoom)\n",
        "\n",
        "        writer.write(frame)\n",
        "        frame_idx += 1\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        fps = frame_idx / elapsed if elapsed > 0 else 0\n",
        "        eta = (total_frames - frame_idx) / fps if fps > 0 else 0\n",
        "        pct = (frame_idx / total_frames) * 100\n",
        "        print(f\"[{frame_idx}/{total_frames}] {pct:.1f}% - {fps:.2f} FPS - ETA: {eta:.1f}s\")\n",
        "\n",
        "    cap.release()\n",
        "    writer.release()\n",
        "    print(f\"✅ Done in {time.time() - start_time:.2f} seconds\")\n"
      ],
      "metadata": {
        "id": "HgITnxPlX154"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_video(VIDEO_PATH, OUTPUT_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSLdOGiSX18B",
        "outputId": "e1e14847-fe3e-491c-91a3-06921b6c80de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pyscenedetect:VideoManager is deprecated and will be removed.\n",
            "INFO:pyscenedetect:Loaded 1 video, framerate: 23.976 FPS, resolution: 1920 x 1080\n",
            "INFO:pyscenedetect:Duration set, start: None, duration: None, end: None.\n",
            "INFO:pyscenedetect:Detecting scenes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected 257 scenes.\n",
            "[1/31151] 0.0% - 0.19 FPS - ETA: 160968.5s\n",
            "[2/31151] 0.0% - 0.25 FPS - ETA: 127025.7s\n",
            "[3/31151] 0.0% - 0.28 FPS - ETA: 109291.4s\n",
            "[4/31151] 0.0% - 0.31 FPS - ETA: 100210.0s\n",
            "[5/31151] 0.0% - 0.33 FPS - ETA: 94966.4s\n",
            "[6/31151] 0.0% - 0.33 FPS - ETA: 93852.7s\n",
            "[7/31151] 0.0% - 0.33 FPS - ETA: 95133.1s\n",
            "[8/31151] 0.0% - 0.34 FPS - ETA: 92497.6s\n",
            "[9/31151] 0.0% - 0.34 FPS - ETA: 90436.9s\n",
            "[10/31151] 0.0% - 0.35 FPS - ETA: 88749.7s\n",
            "[11/31151] 0.0% - 0.35 FPS - ETA: 88082.1s\n",
            "[12/31151] 0.0% - 0.35 FPS - ETA: 89971.7s\n",
            "[13/31151] 0.0% - 0.35 FPS - ETA: 88805.8s\n",
            "[14/31151] 0.0% - 0.35 FPS - ETA: 87733.6s\n",
            "[15/31151] 0.0% - 0.36 FPS - ETA: 86696.9s\n",
            "[16/31151] 0.1% - 0.36 FPS - ETA: 85775.3s\n",
            "[17/31151] 0.1% - 0.36 FPS - ETA: 87084.9s\n",
            "[18/31151] 0.1% - 0.36 FPS - ETA: 86843.0s\n",
            "[19/31151] 0.1% - 0.36 FPS - ETA: 86169.4s\n",
            "[20/31151] 0.1% - 0.36 FPS - ETA: 85566.5s\n",
            "[21/31151] 0.1% - 0.37 FPS - ETA: 84989.7s\n",
            "[22/31151] 0.1% - 0.36 FPS - ETA: 85626.0s\n",
            "[23/31151] 0.1% - 0.36 FPS - ETA: 85923.8s\n",
            "[24/31151] 0.1% - 0.36 FPS - ETA: 85431.8s\n",
            "[25/31151] 0.1% - 0.37 FPS - ETA: 84978.4s\n",
            "[26/31151] 0.1% - 0.37 FPS - ETA: 84544.0s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AXGfCEKpX1-H"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## QA Notes & Validation\n",
        "\n",
        "### Libraries Used & Rationale\n",
        "| Library | Use | Rationale |\n",
        "|--------|-----|-----------|\n",
        "| YOLOv8 | Detection | High-speed, high-accuracy object detection |\n",
        "| Deep SORT | Tracking | Real-time re-identification with long-term memory |\n",
        "| OpenCV | Video I/O | Fast GPU-compatible frame processing |\n",
        "| SceneDetect | Scene splitting | High-confidence video segmentation |\n",
        "| Torch | Inference backend | Optimized for YOLO inference with CUDA |\n",
        "\n",
        "###  QA Parameters to Validate\n",
        "- Smooth zooming around detected subject(s)\n",
        "- No jitter between frames while zooming/panning\n",
        "- Subjects tracked even through partial occlusions\n",
        "- Scene changes respect logical breaks (SceneDetect verified)\n",
        "- Frame rate and resolution are preserved\n",
        "- GPU load and CUDA utilization (`nvidia-smi` check)\n",
        "\n",
        "---\n",
        "\n",
        "Ready to extend with:\n",
        "-  Social media cropping presets (IG, TikTok, etc.)\n",
        "-  Push outputs to cloud\n",
        "-  CI/CD automation via GitHub Actions\n"
      ],
      "metadata": {
        "id": "PijnVDqcbD0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EQJwfISSX2AR"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XkqbK4kgX2CO"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Epwi8T5CX2EK"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dwbB2H_0X2F9"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p9C35GEUX2Jc"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}